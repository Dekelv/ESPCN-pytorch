{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducing ESPCN in the Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this blog, we reproduce the table 1 in paper https://arxiv.org/abs/1609.05158. Based on the already available code https://github.com/yjn870/ESPCN-pytorch, we made several improvements and also reproduced the experiments for 4K and video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How and Why do we need ESPCN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In deep learning research, many researchers have been focusing on the super-resolution problem, which is to upscale a low resolution image to high resolution space. This technique could be used to restore image quality and also could be used in general image processing. In fields like face recognition, medical imaging and also satellite imaging, super resolution has been widely applied. It has also become one of the most popular topics in deep learning area. \n",
    "\n",
    "However, in previous research, the super-resolution operation is carried out in the high resolution space, which, according to the author of the ESPCN paper, is unnecessary and increases the overal computational complexity. Increasing the resolution of the low-resolution images before the image enhancement step increases the computational complexity. And in CNN, the complexity could severly influence the speed of the implementation. Evem more, some traditional interpolation methods used in super-resolution methods can not bring additional information to solve ill-posed problem.\n",
    "\n",
    "While in ESPCN, the upscaling is only performed in the final layer of the network, which greatly increase the efficiency of the model.ALso the ESPCN could obtain additional gains in certain cases. What's more, in ESPCN, no explicit interpolation filter is used. Therefore, the network is able to learn a better mapping from low-resolution image to high-resolution image compared to using a single fixed filter.\n",
    "\n",
    "In ESPCN, an additional deconvolution layer is added. The deconvolutinal layer is a more generic form of the interpolation filter. Thus, more information could be provided when using additional deconvolution layer.\n",
    "\n",
    "An effective way to implement sub-pixel convolution layer is also proposed in the EPSCN. *TBC*\n",
    "\n",
    "In order to verify that ESPCN could actually outperform the previous super-resolution algorithm, we reproduce this paper by using experiments as following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two image datasets used for evaluation are public available benchmark datasets. The first one is the Timofte dataset, which contains 91 training images and two test dataset. The second one is 50,000 randomly selected images from ImageNet for the training.\n",
    "\n",
    "As for video experiments, in the paper, the author uses publicly available Xiph database. *INPUT OUR VIDEO DATASET HERE*\n",
    "\n",
    "According to the paper, the author ran the experiment on a K2 GPU while in our cases, we ran our experiment on our local computer, which is *INPUT YOUR COMPUTER GPU HERE* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the experiment\n",
    "### Network framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c076f21f7a46>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mPython\u001b[0m \u001b[0mcode\u001b[0m \u001b[0mhere\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m '''\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mESPCN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_channels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mESPCN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This is the design of our ESPCN networks, including the intialization \n",
    "weights and forward methods\n",
    "'''\n",
    "import math\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class ESPCN(nn.Module):\n",
    "    def __init__(self, scale_factor, num_channels=1):\n",
    "        super(ESPCN, self).__init__()\n",
    "        self.first_part = nn.Sequential(\n",
    "            nn.Conv2d(num_channels, 64, kernel_size=5, padding=5//2),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=3//2),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        self.last_part = nn.Sequential(\n",
    "            nn.Conv2d(32, num_channels * (scale_factor ** 2), kernel_size=3, padding=3 // 2),\n",
    "            nn.PixelShuffle(scale_factor)\n",
    "        )\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                if m.in_channels == 32:\n",
    "                    nn.init.normal_(m.weight.data, mean=0.0, std=0.001)\n",
    "                    nn.init.zeros_(m.bias.data)\n",
    "                else:\n",
    "                    nn.init.normal_(m.weight.data, mean=0.0, std=math.sqrt(2/(m.out_channels*m.weight.data[0][0].numel())))\n",
    "                    nn.init.zeros_(m.bias.data)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_part(x)\n",
    "        x = self.last_part(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our chosen hyperparameters are as following:\n",
    "\n",
    "scale: 3       \n",
    "\n",
    "learning rate: 1e-3 \n",
    "                \n",
    "batch-size 16 \n",
    "\n",
    "number of epochs: 200 \n",
    "\n",
    "number of workers: 8 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image super resolution\n",
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models import ESPCN\n",
    "from datasets import TrainDataset, EvalDataset\n",
    "from utils import AverageMeter, calc_psnr\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--train-file', type=str, required=True)\n",
    "    parser.add_argument('--eval-file', type=str, required=True)\n",
    "    parser.add_argument('--outputs-dir', type=str, required=True)\n",
    "    parser.add_argument('--weights-file', type=str)\n",
    "    parser.add_argument('--scale', type=int, default=3)\n",
    "    parser.add_argument('--lr', type=float, default=1e-3)\n",
    "    parser.add_argument('--batch-size', type=int, default=16)\n",
    "    parser.add_argument('--num-epochs', type=int, default=200)\n",
    "    parser.add_argument('--num-workers', type=int, default=8)\n",
    "    parser.add_argument('--seed', type=int, default=123)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    args.outputs_dir = os.path.join(args.outputs_dir, 'x{}'.format(args.scale))\n",
    "\n",
    "    if not os.path.exists(args.outputs_dir):\n",
    "        os.makedirs(args.outputs_dir)\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "    model = ESPCN(scale_factor=args.scale).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam([\n",
    "        {'params': model.first_part.parameters()},\n",
    "        {'params': model.last_part.parameters(), 'lr': args.lr * 0.1}\n",
    "    ], lr=args.lr)\n",
    "\n",
    "    train_dataset = TrainDataset(args.train_file)\n",
    "    train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                                  batch_size=args.batch_size,\n",
    "                                  shuffle=True,\n",
    "                                  num_workers=args.num_workers,\n",
    "                                  pin_memory=True)\n",
    "    eval_dataset = EvalDataset(args.eval_file)\n",
    "    eval_dataloader = DataLoader(dataset=eval_dataset, batch_size=1)\n",
    "\n",
    "    best_weights = copy.deepcopy(model.state_dict())\n",
    "    best_epoch = 0\n",
    "    best_psnr = 0.0\n",
    "\n",
    "    for epoch in range(args.num_epochs):\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = args.lr * (0.1 ** (epoch // int(args.num_epochs * 0.8)))\n",
    "\n",
    "        model.train()\n",
    "        epoch_losses = AverageMeter()\n",
    "\n",
    "        with tqdm(total=(len(train_dataset) - len(train_dataset) % args.batch_size), ncols=80) as t:\n",
    "            t.set_description('epoch: {}/{}'.format(epoch, args.num_epochs - 1))\n",
    "\n",
    "            for data in train_dataloader:\n",
    "                inputs, labels = data\n",
    "\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                preds = model(inputs)\n",
    "\n",
    "                loss = criterion(preds, labels)\n",
    "\n",
    "                epoch_losses.update(loss.item(), len(inputs))\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                t.set_postfix(loss='{:.6f}'.format(epoch_losses.avg))\n",
    "                t.update(len(inputs))\n",
    "\n",
    "        torch.save(model.state_dict(), os.path.join(args.outputs_dir, 'epoch_{}.pth'.format(epoch)))\n",
    "\n",
    "        model.eval()\n",
    "        epoch_psnr = AverageMeter()\n",
    "\n",
    "        for data in eval_dataloader:\n",
    "            inputs, labels = data\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                preds = model(inputs).clamp(0.0, 1.0)\n",
    "\n",
    "            epoch_psnr.update(calc_psnr(preds, labels), len(inputs))\n",
    "\n",
    "        print('eval psnr: {:.2f}'.format(epoch_psnr.avg))\n",
    "\n",
    "        if epoch_psnr.avg > best_psnr:\n",
    "            best_epoch = epoch\n",
    "            best_psnr = epoch_psnr.avg\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    print('best epoch: {}, psnr: {:.2f}'.format(best_epoch, best_psnr))\n",
    "    torch.save(best_weights, os.path.join(args.outputs_dir, 'best.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the open source code, we made some improvements on the network ourselves. And by changing the network structure, we could achieve better results compared to before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video super resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
