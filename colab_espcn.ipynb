{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "colab_espcn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pwoxQ6aEjMB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import pandas as pd\n",
        "from torch import nn\n",
        "\n",
        "# Based on the explanation given in the paper,\n",
        "# Number of layers (l) = 3\n",
        "# kernel, i/p (f_i, n_i) where (5,64) -> (3, 32) -> 3\n",
        "# GELU paper https://arxiv.org/pdf/1606.08415v3.pdf\n",
        "# GELU incorporates regularisation (dropout) inherently. It demonstrates improvements in Computer Vision tasks.\n",
        "\n",
        "class ESPCN(nn.Module):\n",
        "    def __init__(self, scale_factor, num_channels=1):\n",
        "        super(ESPCN, self).__init__()\n",
        "        self.first_part = nn.Sequential(\n",
        "            nn.Conv2d(num_channels, 64, kernel_size=5, padding=5//2),\n",
        "            # used GeLU as activation function PSNR -> 32.99\n",
        "            nn.GELU(),\n",
        "            nn.Conv2d(64, 32, kernel_size=3, padding=3//2),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "        # pixel shuffle is basically up-sampling the data from LR -> HR\n",
        "        self.last_part = nn.Sequential(\n",
        "            nn.Conv2d(32, num_channels * (scale_factor ** 2), kernel_size=3, padding=3 // 2),\n",
        "            nn.PixelShuffle(scale_factor)\n",
        "        )\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                if m.in_channels == 32:\n",
        "                    nn.init.normal_(m.weight.data, mean=0.0, std=0.001)\n",
        "                    nn.init.zeros_(m.bias.data)\n",
        "                else:\n",
        "                    nn.init.normal_(m.weight.data, mean=0.0, std=math.sqrt(2/(m.out_channels*m.weight.data[0][0].numel())))\n",
        "                    nn.init.zeros_(m.bias.data)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.first_part(x)\n",
        "        x = self.last_part(x)\n",
        "        return x\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cM5GgBzFU14m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class TrainDataset(Dataset):\n",
        "    def __init__(self, h5_file):\n",
        "        super(TrainDataset, self).__init__()\n",
        "        self.h5_file = h5_file\n",
        "\n",
        "    # returns the data points with 'lr' as inputs and 'hr' as labels\n",
        "    def __getitem__(self, idx):\n",
        "        with h5py.File(self.h5_file, 'r') as f:\n",
        "            return np.expand_dims(f['lr'][idx] / 255., 0), np.expand_dims(f['hr'][idx] / 255., 0)\n",
        "\n",
        "    def __len__(self):\n",
        "        with h5py.File(self.h5_file, 'r') as f:\n",
        "            return len(f['lr'])\n",
        "\n",
        "\n",
        "class EvalDataset(Dataset):\n",
        "    def __init__(self, h5_file):\n",
        "        super(EvalDataset, self).__init__()\n",
        "        self.h5_file = h5_file\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        with h5py.File(self.h5_file, 'r') as f:\n",
        "            return np.expand_dims(f['lr'][str(idx)][:, :] / 255., 0), np.expand_dims(f['hr'][str(idx)][:, :] / 255., 0)\n",
        "\n",
        "    def __len__(self):\n",
        "        with h5py.File(self.h5_file, 'r') as f:\n",
        "            return len(f['lr'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YC40IEcgU92O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def calc_patch_size(func):\n",
        "    def wrapper(args):\n",
        "        if args.scale == 2:\n",
        "            args.patch_size = 10\n",
        "        elif args.scale == 3:\n",
        "            args.patch_size = 7\n",
        "        elif args.scale == 4:\n",
        "            args.patch_size = 6\n",
        "        else:\n",
        "            raise Exception('Scale Error', args.scale)\n",
        "        return func(args)\n",
        "    return wrapper\n",
        "\n",
        "\n",
        "def convert_rgb_to_y(img, dim_order='hwc'):\n",
        "    if dim_order == 'hwc':\n",
        "        return 16. + (64.738 * img[..., 0] + 129.057 * img[..., 1] + 25.064 * img[..., 2]) / 256.\n",
        "    else:\n",
        "        return 16. + (64.738 * img[0] + 129.057 * img[1] + 25.064 * img[2]) / 256.\n",
        "\n",
        "\n",
        "def convert_rgb_to_ycbcr(img, dim_order='hwc'):\n",
        "    if dim_order == 'hwc':\n",
        "        y = 16. + (64.738 * img[..., 0] + 129.057 * img[..., 1] + 25.064 * img[..., 2]) / 256.\n",
        "        cb = 128. + (-37.945 * img[..., 0] - 74.494 * img[..., 1] + 112.439 * img[..., 2]) / 256.\n",
        "        cr = 128. + (112.439 * img[..., 0] - 94.154 * img[..., 1] - 18.285 * img[..., 2]) / 256.\n",
        "    else:\n",
        "        y = 16. + (64.738 * img[0] + 129.057 * img[1] + 25.064 * img[2]) / 256.\n",
        "        cb = 128. + (-37.945 * img[0] - 74.494 * img[1] + 112.439 * img[2]) / 256.\n",
        "        cr = 128. + (112.439 * img[0] - 94.154 * img[1] - 18.285 * img[2]) / 256.\n",
        "    return np.array([y, cb, cr]).transpose([1, 2, 0])\n",
        "\n",
        "\n",
        "def convert_ycbcr_to_rgb(img, dim_order='hwc'):\n",
        "    if dim_order == 'hwc':\n",
        "        r = 298.082 * img[..., 0] / 256. + 408.583 * img[..., 2] / 256. - 222.921\n",
        "        g = 298.082 * img[..., 0] / 256. - 100.291 * img[..., 1] / 256. - 208.120 * img[..., 2] / 256. + 135.576\n",
        "        b = 298.082 * img[..., 0] / 256. + 516.412 * img[..., 1] / 256. - 276.836\n",
        "    else:\n",
        "        r = 298.082 * img[0] / 256. + 408.583 * img[2] / 256. - 222.921\n",
        "        g = 298.082 * img[0] / 256. - 100.291 * img[1] / 256. - 208.120 * img[2] / 256. + 135.576\n",
        "        b = 298.082 * img[0] / 256. + 516.412 * img[1] / 256. - 276.836\n",
        "    return np.array([r, g, b]).transpose([1, 2, 0])\n",
        "\n",
        "\n",
        "def preprocess(img, device):\n",
        "    img = np.array(img).astype(np.float32)\n",
        "    ycbcr = convert_rgb_to_ycbcr(img)\n",
        "    x = ycbcr[..., 0]\n",
        "    x /= 255.\n",
        "    x = torch.from_numpy(x).to(device)\n",
        "    x = x.unsqueeze(0).unsqueeze(0)\n",
        "    return x, ycbcr\n",
        "\n",
        "\n",
        "def calc_psnr(img1, img2):\n",
        "    return 10. * torch.log10(1. / torch.mean((img1 - img2) ** 2))\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6fern58Ungv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "import copy\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "# from models import ESPCN\n",
        "# from datasets import TrainDataset, EvalDataset\n",
        "# from utils import AverageMeter, calc_psnr\n",
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "    # parser = argparse.ArgumentParser()\n",
        "    # parser.add_argument('--train-file', type=str, required=True)\n",
        "    # parser.add_argument('--eval-file', type=str, required=True)\n",
        "    # parser.add_argument('--outputs-dir', type=str, required=True)\n",
        "    # parser.add_argument('--weights-file', type=str)\n",
        "    # parser.add_argument('--scale', type=int, default=3)\n",
        "    # parser.add_argument('--lr', type=float, default=1e-3)\n",
        "    # parser.add_argument('--batch-size', type=int, default=16)\n",
        "    # parser.add_argument('--num-epochs', type=int, default=200)\n",
        "    # parser.add_argument('--num-workers', type=int, default=8)\n",
        "    # parser.add_argument('--seed', type=int, default=123)\n",
        "    # args = parser.parse_args()\n",
        "def train(args):\n",
        "  # this is where the x3 comes from\n",
        "    # args.outputs_dir = os.path.join(args.outputs_dir, 'x{}'.format(args.scale))\n",
        "\n",
        "# check for drive path\n",
        "    # if not os.path.exists(args.outputs_dir):\n",
        "    #     os.makedirs(args.outputs_dir)\n",
        "\n",
        "    cudnn.benchmark = True\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    torch.manual_seed(args.seed)\n",
        "    # Init ESPCN model from models.py\n",
        "    model = ESPCN(scale_factor=args.scale).to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    # lr is learning rate... where do they get this calculation for the last part from?\n",
        "    optimizer = optim.Adam([\n",
        "        {'params': model.first_part.parameters()},\n",
        "        {'params': model.last_part.parameters(), 'lr': args.lr * 0.1}\n",
        "    ], lr=args.lr)\n",
        "\n",
        "    # Brings the training data and does some processing\n",
        "    train_dataset = TrainDataset(args.train_file)\n",
        "    train_dataloader = DataLoader(dataset=train_dataset,\n",
        "                                  batch_size=args.batch_size,\n",
        "                                  shuffle=True,\n",
        "                                  num_workers=args.num_workers,\n",
        "                                  pin_memory=True)\n",
        "    eval_dataset = EvalDataset(args.eval_file)\n",
        "    eval_dataloader = DataLoader(dataset=eval_dataset, batch_size=1)\n",
        "\n",
        "    best_weights = copy.deepcopy(model.state_dict())\n",
        "    best_epoch = 0\n",
        "    best_psnr = 0.0\n",
        "\n",
        "    for epoch in range(args.num_epochs):\n",
        "        # A time decaying learning rate\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = args.lr * (0.1 ** (epoch // int(args.num_epochs * 0.8)))\n",
        "\n",
        "        # Train mode\n",
        "        model.train()\n",
        "        epoch_losses = AverageMeter()\n",
        "\n",
        "        with tqdm(total=(len(train_dataset) - len(train_dataset) % args.batch_size), ncols=80) as t:\n",
        "            t.set_description('epoch: {}/{}'.format(epoch, args.num_epochs - 1))\n",
        "\n",
        "            for data in train_dataloader:\n",
        "                inputs, labels = data\n",
        "\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Core Model\n",
        "                preds = model(inputs)\n",
        "                loss = criterion(preds, labels)\n",
        "                # this must update the values with a user defined function\n",
        "                epoch_losses.update(loss.item(), len(inputs))\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                # edit the print string for tqdm\n",
        "                t.set_postfix(loss='{:.6f}'.format(epoch_losses.avg))\n",
        "                t.update(len(inputs))\n",
        "\n",
        "        torch.save(model.state_dict(), os.path.join(args.outputs_dir, 'epoch_{}.pth'.format(epoch)))\n",
        "\n",
        "        model.eval()\n",
        "        epoch_psnr = AverageMeter()\n",
        "\n",
        "        for data in eval_dataloader:\n",
        "            inputs, labels = data\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                preds = model(inputs).clamp(0.0, 1.0)\n",
        "\n",
        "            epoch_psnr.update(calc_psnr(preds, labels), len(inputs))\n",
        "\n",
        "        print('eval psnr: {:.2f}'.format(epoch_psnr.avg))\n",
        "\n",
        "        if epoch_psnr.avg > best_psnr:\n",
        "            best_epoch = epoch\n",
        "            best_psnr = epoch_psnr.avg\n",
        "            best_weights = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    print('best epoch: {}, psnr: {:.2f}'.format(best_epoch, best_psnr))\n",
        "    torch.save(best_weights, os.path.join(args.outputs_dir, 'best.pth'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSxWrPvRXX7p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        },
        "outputId": "f6cbc7e7-3442-4d74-9f99-deeeae8e6405"
      },
      "source": [
        "from typing import NamedTuple\n",
        "\n",
        "class Train_args(NamedTuple):\n",
        "    train_file: str\n",
        "    eval_file: str\n",
        "    outputs_dir: str\n",
        "    weights_file: str\n",
        "    scale: int\n",
        "    lr: float\n",
        "    batch_size: int\n",
        "    num_epochs: int\n",
        "    num_workers: int\n",
        "    seed: int\n",
        "\n",
        "train_args = Train_args(\"./drive/My Drive/espcn/91-image_x3.h5\", \"./drive/My Drive/espcn/Set5_x3.h5\",\"./drive/My Drive/espcn/outputs\",'',3,1e-3, 16, 200, 8, 123)\n",
        "# train_args.batch_size\n",
        "train(train_args)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0/199:  10%|â–ˆ         | 272/2688 [00:01<00:09, 256.13it/s, loss=0.099730]\n",
            "Exception in thread Thread-16:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 864, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 25, in _pin_memory_loop\n",
            "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 113, in get\n",
            "    return _ForkingPickler.loads(res)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/multiprocessing/reductions.py\", line 294, in rebuild_storage_fd\n",
            "    fd = df.detach()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/resource_sharer.py\", line 57, in detach\n",
            "    with _resource_sharer.get_connection(self._id) as conn:\n",
            "  File \"/usr/lib/python3.6/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
            "    c = Client(address, authkey=process.current_process().authkey)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 487, in Client\n",
            "    c = SocketClient(address)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 614, in SocketClient\n",
            "    s.connect(address)\n",
            "FileNotFoundError: [Errno 2] No such file or directory\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-ba9fd3669b1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mtrain_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrain_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./drive/My Drive/espcn/91-image_x3.h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./drive/My Drive/espcn/Set5_x3.h5\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"./drive/My Drive/espcn/outputs\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m123\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# train_args.batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-7ca68cd26602>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch: {}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjAVTTxJYH3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "import numpy as np\n",
        "import PIL.Image as pil_image\n",
        "\n",
        "from models import ESPCN\n",
        "from utils import convert_ycbcr_to_rgb, preprocess, calc_psnr\n",
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     parser = argparse.ArgumentParser()\n",
        "#     parser.add_argument('--weights-file', type=str, required=True)\n",
        "#     parser.add_argument('--image-file', type=str, required=True)\n",
        "#     parser.add_argument('--scale', type=int, default=3)\n",
        "#     args = parser.parse_args()\n",
        "def test(args):\n",
        "\n",
        "    cudnn.benchmark = True\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    model = ESPCN(scale_factor=args.scale).to(device)\n",
        "\n",
        "    state_dict = model.state_dict()\n",
        "    for n, p in torch.load(args.weights_file, map_location=lambda storage, loc: storage).items():\n",
        "        if n in state_dict.keys():\n",
        "            state_dict[n].copy_(p)\n",
        "        else:\n",
        "            raise KeyError(n)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    image = pil_image.open(args.image_file).convert('RGB')\n",
        "\n",
        "    image_width = (image.width // args.scale) * args.scale\n",
        "    image_height = (image.height // args.scale) * args.scale\n",
        "\n",
        "    hr = image.resize((image_width, image_height), resample=pil_image.BICUBIC)\n",
        "    lr = hr.resize((hr.width // args.scale, hr.height // args.scale), resample=pil_image.BICUBIC)\n",
        "    bicubic = lr.resize((lr.width * args.scale, lr.height * args.scale), resample=pil_image.BICUBIC)\n",
        "    bicubic.save(args.image_file.replace('.', '_bicubic_x{}.'.format(args.scale)))\n",
        "\n",
        "    lr, _ = preprocess(lr, device)\n",
        "    hr, _ = preprocess(hr, device)\n",
        "    _, ycbcr = preprocess(bicubic, device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        preds = model(lr).clamp(0.0, 1.0)\n",
        "\n",
        "    psnr = calc_psnr(hr, preds)\n",
        "    print('PSNR: {:.2f}'.format(psnr))\n",
        "\n",
        "    preds = preds.mul(255.0).cpu().numpy().squeeze(0).squeeze(0)\n",
        "\n",
        "    output = np.array([preds, ycbcr[..., 1], ycbcr[..., 2]]).transpose([1, 2, 0])\n",
        "    output = np.clip(convert_ycbcr_to_rgb(output), 0.0, 255.0).astype(np.uint8)\n",
        "    output = pil_image.fromarray(output)\n",
        "    output.save(args.image_file.replace('.', '_espcn_x{}.'.format(args.scale)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuz2W5u9YQ-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_args = {\"weights_file\": \"./drive/My Drive/espcn/outputs/x3/best.pth\", \"scale\": 3}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgvOL9KjaR4f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "47592b0f-8494-4eab-d27e-268a67c7954b"
      },
      "source": [
        "pd.read_csv('./drive/My Drive/espcn/50_Startups.csv')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>R&amp;D Spend</th>\n",
              "      <th>Administration</th>\n",
              "      <th>Marketing Spend</th>\n",
              "      <th>State</th>\n",
              "      <th>Profit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>165349.20</td>\n",
              "      <td>136897.80</td>\n",
              "      <td>471784.10</td>\n",
              "      <td>New York</td>\n",
              "      <td>192261.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>162597.70</td>\n",
              "      <td>151377.59</td>\n",
              "      <td>443898.53</td>\n",
              "      <td>California</td>\n",
              "      <td>191792.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>153441.51</td>\n",
              "      <td>101145.55</td>\n",
              "      <td>407934.54</td>\n",
              "      <td>Florida</td>\n",
              "      <td>191050.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>144372.41</td>\n",
              "      <td>118671.85</td>\n",
              "      <td>383199.62</td>\n",
              "      <td>New York</td>\n",
              "      <td>182901.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>142107.34</td>\n",
              "      <td>91391.77</td>\n",
              "      <td>366168.42</td>\n",
              "      <td>Florida</td>\n",
              "      <td>166187.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>131876.90</td>\n",
              "      <td>99814.71</td>\n",
              "      <td>362861.36</td>\n",
              "      <td>New York</td>\n",
              "      <td>156991.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>134615.46</td>\n",
              "      <td>147198.87</td>\n",
              "      <td>127716.82</td>\n",
              "      <td>California</td>\n",
              "      <td>156122.51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>130298.13</td>\n",
              "      <td>145530.06</td>\n",
              "      <td>323876.68</td>\n",
              "      <td>Florida</td>\n",
              "      <td>155752.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>120542.52</td>\n",
              "      <td>148718.95</td>\n",
              "      <td>311613.29</td>\n",
              "      <td>New York</td>\n",
              "      <td>152211.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>123334.88</td>\n",
              "      <td>108679.17</td>\n",
              "      <td>304981.62</td>\n",
              "      <td>California</td>\n",
              "      <td>149759.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>101913.08</td>\n",
              "      <td>110594.11</td>\n",
              "      <td>229160.95</td>\n",
              "      <td>Florida</td>\n",
              "      <td>146121.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>100671.96</td>\n",
              "      <td>91790.61</td>\n",
              "      <td>249744.55</td>\n",
              "      <td>California</td>\n",
              "      <td>144259.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>93863.75</td>\n",
              "      <td>127320.38</td>\n",
              "      <td>249839.44</td>\n",
              "      <td>Florida</td>\n",
              "      <td>141585.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>91992.39</td>\n",
              "      <td>135495.07</td>\n",
              "      <td>252664.93</td>\n",
              "      <td>California</td>\n",
              "      <td>134307.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>119943.24</td>\n",
              "      <td>156547.42</td>\n",
              "      <td>256512.92</td>\n",
              "      <td>Florida</td>\n",
              "      <td>132602.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>114523.61</td>\n",
              "      <td>122616.84</td>\n",
              "      <td>261776.23</td>\n",
              "      <td>New York</td>\n",
              "      <td>129917.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>78013.11</td>\n",
              "      <td>121597.55</td>\n",
              "      <td>264346.06</td>\n",
              "      <td>California</td>\n",
              "      <td>126992.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>94657.16</td>\n",
              "      <td>145077.58</td>\n",
              "      <td>282574.31</td>\n",
              "      <td>New York</td>\n",
              "      <td>125370.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>91749.16</td>\n",
              "      <td>114175.79</td>\n",
              "      <td>294919.57</td>\n",
              "      <td>Florida</td>\n",
              "      <td>124266.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>86419.70</td>\n",
              "      <td>153514.11</td>\n",
              "      <td>0.00</td>\n",
              "      <td>New York</td>\n",
              "      <td>122776.86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>76253.86</td>\n",
              "      <td>113867.30</td>\n",
              "      <td>298664.47</td>\n",
              "      <td>California</td>\n",
              "      <td>118474.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>78389.47</td>\n",
              "      <td>153773.43</td>\n",
              "      <td>299737.29</td>\n",
              "      <td>New York</td>\n",
              "      <td>111313.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>73994.56</td>\n",
              "      <td>122782.75</td>\n",
              "      <td>303319.26</td>\n",
              "      <td>Florida</td>\n",
              "      <td>110352.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>67532.53</td>\n",
              "      <td>105751.03</td>\n",
              "      <td>304768.73</td>\n",
              "      <td>Florida</td>\n",
              "      <td>108733.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>77044.01</td>\n",
              "      <td>99281.34</td>\n",
              "      <td>140574.81</td>\n",
              "      <td>New York</td>\n",
              "      <td>108552.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>64664.71</td>\n",
              "      <td>139553.16</td>\n",
              "      <td>137962.62</td>\n",
              "      <td>California</td>\n",
              "      <td>107404.34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>75328.87</td>\n",
              "      <td>144135.98</td>\n",
              "      <td>134050.07</td>\n",
              "      <td>Florida</td>\n",
              "      <td>105733.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>72107.60</td>\n",
              "      <td>127864.55</td>\n",
              "      <td>353183.81</td>\n",
              "      <td>New York</td>\n",
              "      <td>105008.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>66051.52</td>\n",
              "      <td>182645.56</td>\n",
              "      <td>118148.20</td>\n",
              "      <td>Florida</td>\n",
              "      <td>103282.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>65605.48</td>\n",
              "      <td>153032.06</td>\n",
              "      <td>107138.38</td>\n",
              "      <td>New York</td>\n",
              "      <td>101004.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>61994.48</td>\n",
              "      <td>115641.28</td>\n",
              "      <td>91131.24</td>\n",
              "      <td>Florida</td>\n",
              "      <td>99937.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>61136.38</td>\n",
              "      <td>152701.92</td>\n",
              "      <td>88218.23</td>\n",
              "      <td>New York</td>\n",
              "      <td>97483.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>63408.86</td>\n",
              "      <td>129219.61</td>\n",
              "      <td>46085.25</td>\n",
              "      <td>California</td>\n",
              "      <td>97427.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>55493.95</td>\n",
              "      <td>103057.49</td>\n",
              "      <td>214634.81</td>\n",
              "      <td>Florida</td>\n",
              "      <td>96778.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>46426.07</td>\n",
              "      <td>157693.92</td>\n",
              "      <td>210797.67</td>\n",
              "      <td>California</td>\n",
              "      <td>96712.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>46014.02</td>\n",
              "      <td>85047.44</td>\n",
              "      <td>205517.64</td>\n",
              "      <td>New York</td>\n",
              "      <td>96479.51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>28663.76</td>\n",
              "      <td>127056.21</td>\n",
              "      <td>201126.82</td>\n",
              "      <td>Florida</td>\n",
              "      <td>90708.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>44069.95</td>\n",
              "      <td>51283.14</td>\n",
              "      <td>197029.42</td>\n",
              "      <td>California</td>\n",
              "      <td>89949.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>20229.59</td>\n",
              "      <td>65947.93</td>\n",
              "      <td>185265.10</td>\n",
              "      <td>New York</td>\n",
              "      <td>81229.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>38558.51</td>\n",
              "      <td>82982.09</td>\n",
              "      <td>174999.30</td>\n",
              "      <td>California</td>\n",
              "      <td>81005.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>28754.33</td>\n",
              "      <td>118546.05</td>\n",
              "      <td>172795.67</td>\n",
              "      <td>California</td>\n",
              "      <td>78239.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>27892.92</td>\n",
              "      <td>84710.77</td>\n",
              "      <td>164470.71</td>\n",
              "      <td>Florida</td>\n",
              "      <td>77798.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>23640.93</td>\n",
              "      <td>96189.63</td>\n",
              "      <td>148001.11</td>\n",
              "      <td>California</td>\n",
              "      <td>71498.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>15505.73</td>\n",
              "      <td>127382.30</td>\n",
              "      <td>35534.17</td>\n",
              "      <td>New York</td>\n",
              "      <td>69758.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>22177.74</td>\n",
              "      <td>154806.14</td>\n",
              "      <td>28334.72</td>\n",
              "      <td>California</td>\n",
              "      <td>65200.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>1000.23</td>\n",
              "      <td>124153.04</td>\n",
              "      <td>1903.93</td>\n",
              "      <td>New York</td>\n",
              "      <td>64926.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>1315.46</td>\n",
              "      <td>115816.21</td>\n",
              "      <td>297114.46</td>\n",
              "      <td>Florida</td>\n",
              "      <td>49490.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.00</td>\n",
              "      <td>135426.92</td>\n",
              "      <td>0.00</td>\n",
              "      <td>California</td>\n",
              "      <td>42559.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>542.05</td>\n",
              "      <td>51743.15</td>\n",
              "      <td>0.00</td>\n",
              "      <td>New York</td>\n",
              "      <td>35673.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>0.00</td>\n",
              "      <td>116983.80</td>\n",
              "      <td>45173.06</td>\n",
              "      <td>California</td>\n",
              "      <td>14681.40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    R&D Spend  Administration  Marketing Spend       State     Profit\n",
              "0   165349.20       136897.80        471784.10    New York  192261.83\n",
              "1   162597.70       151377.59        443898.53  California  191792.06\n",
              "2   153441.51       101145.55        407934.54     Florida  191050.39\n",
              "3   144372.41       118671.85        383199.62    New York  182901.99\n",
              "4   142107.34        91391.77        366168.42     Florida  166187.94\n",
              "5   131876.90        99814.71        362861.36    New York  156991.12\n",
              "6   134615.46       147198.87        127716.82  California  156122.51\n",
              "7   130298.13       145530.06        323876.68     Florida  155752.60\n",
              "8   120542.52       148718.95        311613.29    New York  152211.77\n",
              "9   123334.88       108679.17        304981.62  California  149759.96\n",
              "10  101913.08       110594.11        229160.95     Florida  146121.95\n",
              "11  100671.96        91790.61        249744.55  California  144259.40\n",
              "12   93863.75       127320.38        249839.44     Florida  141585.52\n",
              "13   91992.39       135495.07        252664.93  California  134307.35\n",
              "14  119943.24       156547.42        256512.92     Florida  132602.65\n",
              "15  114523.61       122616.84        261776.23    New York  129917.04\n",
              "16   78013.11       121597.55        264346.06  California  126992.93\n",
              "17   94657.16       145077.58        282574.31    New York  125370.37\n",
              "18   91749.16       114175.79        294919.57     Florida  124266.90\n",
              "19   86419.70       153514.11             0.00    New York  122776.86\n",
              "20   76253.86       113867.30        298664.47  California  118474.03\n",
              "21   78389.47       153773.43        299737.29    New York  111313.02\n",
              "22   73994.56       122782.75        303319.26     Florida  110352.25\n",
              "23   67532.53       105751.03        304768.73     Florida  108733.99\n",
              "24   77044.01        99281.34        140574.81    New York  108552.04\n",
              "25   64664.71       139553.16        137962.62  California  107404.34\n",
              "26   75328.87       144135.98        134050.07     Florida  105733.54\n",
              "27   72107.60       127864.55        353183.81    New York  105008.31\n",
              "28   66051.52       182645.56        118148.20     Florida  103282.38\n",
              "29   65605.48       153032.06        107138.38    New York  101004.64\n",
              "30   61994.48       115641.28         91131.24     Florida   99937.59\n",
              "31   61136.38       152701.92         88218.23    New York   97483.56\n",
              "32   63408.86       129219.61         46085.25  California   97427.84\n",
              "33   55493.95       103057.49        214634.81     Florida   96778.92\n",
              "34   46426.07       157693.92        210797.67  California   96712.80\n",
              "35   46014.02        85047.44        205517.64    New York   96479.51\n",
              "36   28663.76       127056.21        201126.82     Florida   90708.19\n",
              "37   44069.95        51283.14        197029.42  California   89949.14\n",
              "38   20229.59        65947.93        185265.10    New York   81229.06\n",
              "39   38558.51        82982.09        174999.30  California   81005.76\n",
              "40   28754.33       118546.05        172795.67  California   78239.91\n",
              "41   27892.92        84710.77        164470.71     Florida   77798.83\n",
              "42   23640.93        96189.63        148001.11  California   71498.49\n",
              "43   15505.73       127382.30         35534.17    New York   69758.98\n",
              "44   22177.74       154806.14         28334.72  California   65200.33\n",
              "45    1000.23       124153.04          1903.93    New York   64926.08\n",
              "46    1315.46       115816.21        297114.46     Florida   49490.75\n",
              "47       0.00       135426.92             0.00  California   42559.73\n",
              "48     542.05        51743.15             0.00    New York   35673.41\n",
              "49       0.00       116983.80         45173.06  California   14681.40"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ds7GNGAGazmc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}